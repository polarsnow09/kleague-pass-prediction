"""
ì•™ìƒë¸” ì˜ˆì¸¡ (XGBoost + LightGBM)
Kë¦¬ê·¸ íŒ¨ìŠ¤ ì¢Œí‘œ ì˜ˆì¸¡
"""

import numpy as np
import pandas as pd
from pathlib import Path
from tqdm import tqdm
import sys
import pickle

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent))
from src.features.build_feature import build_baseline_features, add_previous_action_features

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / 'data'
MODEL_DIR = PROJECT_ROOT / 'models'
OUTPUT_DIR = PROJECT_ROOT / 'submissions'

OUTPUT_DIR.mkdir(exist_ok=True)


class EnsemblePredictor:
    """ì•™ìƒë¸” ì˜ˆì¸¡ê¸° (ì—¬ëŸ¬ ëª¨ë¸ í‰ê· )"""
    
    def __init__(self, model_paths: list, weights: list = None):
        """
        Args:
            model_paths: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            weights: ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ (Noneì´ë©´ ê· ë“± í‰ê· )
        """
        self.models = []
        self.feature_cols = None
        
        print(f"ğŸ“¦ ëª¨ë¸ ë¡œë”© ({len(model_paths)}ê°œ)")
        
        for i, path in enumerate(model_paths, 1):
            print(f"  {i}. {path.name}")
            with open(path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.models.append({
                'model_x': model_data['model_x'],
                'model_y': model_data['model_y'],
                'feature_cols': model_data['feature_cols'],
                'name': path.stem
            })
            
            # ì²« ë²ˆì§¸ ëª¨ë¸ì˜ í”¼ì²˜ ì»¬ëŸ¼ ì‚¬ìš©
            if self.feature_cols is None:
                self.feature_cols = model_data['feature_cols']
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        if weights is None:
            self.weights = [1.0 / len(self.models)] * len(self.models)
        else:
            self.weights = weights
        
        print(f"âœ… ì•™ìƒë¸” ì¤€ë¹„ ì™„ë£Œ")
        print(f"  - ëª¨ë¸ ìˆ˜: {len(self.models)}")
        print(f"  - ê°€ì¤‘ì¹˜: {self.weights}")
        print(f"  - í”¼ì²˜ ìˆ˜: {len(self.feature_cols)}")
    
    def load_test_episode(self, csv_path: Path) -> pd.DataFrame:
        """Test episode CSV ë¡œë“œ"""
        if not csv_path.exists():
            raise FileNotFoundError(f"íŒŒì¼ ì—†ìŒ: {csv_path}")
        
        df = pd.read_csv(csv_path)
        
        if 'end_x' not in df.columns:
            df['end_x'] = df['start_x']
        if 'end_y' not in df.columns:
            df['end_y'] = df['start_y']
        
        df['game_episode'] = 'temp'
        
        if 'is_home' not in df.columns:
            df['is_home'] = 1
        
        return df
    
    def preprocess_episode(self, df: pd.DataFrame) -> pd.DataFrame:
        """í”¼ì²˜ ìƒì„±"""
        df = build_baseline_features(df)
        df = add_previous_action_features(df)
        return df
    
    def prepare_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ëª¨ë¸ ì…ë ¥ í”¼ì²˜ ì¤€ë¹„"""
        df = df.copy()
        
        # ë²”ì£¼í˜• ì¸ì½”ë”©
        zone_x_map = {'defensive': 0, 'midfield': 1, 'attacking': 2}
        zone_y_map = {'left': 0, 'center': 1, 'right': 2}
        zone_combined_map = {
            'defensive_left': 0, 'defensive_center': 1, 'defensive_right': 2,
            'midfield_left': 3, 'midfield_center': 4, 'midfield_right': 5,
            'attacking_left': 6, 'attacking_center': 7, 'attacking_right': 8
        }
        
        if 'zone_x' in df.columns:
            df['zone_x_encoded'] = df['zone_x'].astype(str).map(zone_x_map)
            df['zone_y_encoded'] = df['zone_y'].astype(str).map(zone_y_map)
            df['zone_combined_encoded'] = df['zone_combined'].astype(str).map(zone_combined_map)
        
        # ëˆ„ë½ëœ í”¼ì²˜ ì²˜ë¦¬
        for feat in self.feature_cols:
            if feat not in df.columns:
                df[feat] = 0
        
        X = df[self.feature_cols].copy()
        X = X.fillna(0)
        
        return X
    
    def predict(self, X: pd.DataFrame) -> tuple:
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        pred_x_list = []
        pred_y_list = []
        
        for model_info, weight in zip(self.models, self.weights):
            pred_x = model_info['model_x'].predict(X)
            pred_y = model_info['model_y'].predict(X)
            
            pred_x_list.append(pred_x * weight)
            pred_y_list.append(pred_y * weight)
        
        # ê°€ì¤‘ í‰ê· 
        final_pred_x = np.sum(pred_x_list, axis=0)
        final_pred_y = np.sum(pred_y_list, axis=0)
        
        return final_pred_x, final_pred_y
    
    def predict_episode(self, csv_path: Path, debug: bool = False) -> tuple:
        """Episode ì˜ˆì¸¡"""
        df = self.load_test_episode(csv_path)
        
        if debug:
            print(f"\n  ğŸ” {csv_path.name}")
            print(f"    - ì›ë³¸ í–‰ ìˆ˜: {len(df)}")
        
        df = self.preprocess_episode(df)
        
        if debug:
            print(f"    - ì „ì²˜ë¦¬ í›„: {len(df.columns)}ê°œ ì»¬ëŸ¼")
        
        last_row = df.iloc[[-1]].copy()
        X = self.prepare_features(last_row)
        
        if debug:
            print(f"    - í”¼ì²˜ ì¤€ë¹„ ì™„ë£Œ: {X.shape}")
        
        pred_x, pred_y = self.predict(X)
        
        if debug:
            print(f"    - ì˜ˆì¸¡: ({pred_x[0]:.2f}, {pred_y[0]:.2f})")
        
        return pred_x[0], pred_y[0]


def create_ensemble_submission(
    test_csv: Path,
    model_paths: list,
    weights: list = None,
    output_filename: str = 'submission_ensemble.csv',
    debug_first_n: int = 5
) -> None:
    """ì•™ìƒë¸” ì œì¶œ íŒŒì¼ ìƒì„±"""
    print("=" * 60)
    print("ğŸ¯ Kë¦¬ê·¸ íŒ¨ìŠ¤ ì¢Œí‘œ ì˜ˆì¸¡ - ì•™ìƒë¸” ì œì¶œ")
    print("=" * 60)
    
    # Test ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“‚ Test ë°ì´í„° ë¡œë”©: {test_csv}")
    test_df = pd.read_csv(test_csv)
    print(f"  - ì˜ˆì¸¡ ëŒ€ìƒ: {len(test_df)}ê°œ episode")
    
    # ì•™ìƒë¸” ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
    predictor = EnsemblePredictor(model_paths, weights)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    print(f"\nğŸ”® ì˜ˆì¸¡ ì‹œì‘...")
    predictions = []
    errors = []
    
    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc="ì˜ˆì¸¡ ì¤‘"):
        game_episode = row['game_episode']
        
        relative_path = row['path']
        if relative_path.startswith('./'):
            relative_path = relative_path[2:]
        
        csv_path = DATA_DIR / 'raw' / relative_path
        
        try:
            debug = (idx < debug_first_n)
            end_x, end_y = predictor.predict_episode(csv_path, debug=debug)
            
            predictions.append({
                'game_episode': game_episode,
                'end_x': end_x,
                'end_y': end_y
            })
            
        except FileNotFoundError:
            errors.append(str(csv_path))
            predictions.append({
                'game_episode': game_episode,
                'end_x': 52.5,
                'end_y': 34.0
            })
            
        except Exception as e:
            print(f"\nâš ï¸  ì˜¤ë¥˜ ({game_episode}): {e}")
            predictions.append({
                'game_episode': game_episode,
                'end_x': 52.5,
                'end_y': 34.0
            })
    
    if errors:
        print(f"\nâš ï¸  íŒŒì¼ ì—†ìŒ: {len(errors)}ê°œ")
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    print(f"\nğŸ’¾ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    submission = pd.DataFrame(predictions)
    
    # ì¢Œí‘œ ë²”ìœ„ ì²´í¬
    submission['end_x'] = submission['end_x'].clip(0, 105)
    submission['end_y'] = submission['end_y'].clip(0, 68)
    
    # ì €ì¥
    output_path = OUTPUT_DIR / output_filename
    submission.to_csv(output_path, index=False)
    
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"\nğŸ“Š ì˜ˆì¸¡ í†µê³„:")
    print(submission[['end_x', 'end_y']].describe())
    
    success_rate = (len(test_df) - len(errors)) / len(test_df) * 100
    print(f"\nì„±ê³µë¥ : {success_rate:.1f}% ({len(test_df) - len(errors)}/{len(test_df)})")
    
    print("\n" + "=" * 60)
    print("ğŸŠ ì•™ìƒë¸” ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
    print("=" * 60)


if __name__ == '__main__':
    # ì„¤ì •
    TEST_CSV = DATA_DIR / 'raw' / 'test.csv'
    
    # ì•™ìƒë¸”í•  ëª¨ë¸ë“¤
    MODEL_PATHS = [
        MODEL_DIR / 'baseline_model_v2_temporal.pkl',  # XGBoost
        MODEL_DIR / 'lgb_model_v1.pkl',                # LightGBM
        MODEL_DIR / 'catboost_model_v1.pkl',            # CatBoost
    ]
    
    # ëª¨ë¸ ì¡´ì¬ í™•ì¸
    for path in MODEL_PATHS:
        if not path.exists():
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {path}")
            print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
            for model_file in MODEL_DIR.glob('*.pkl'):
                print(f"  - {model_file.name}")
            exit(1)
    
    if not TEST_CSV.exists():
        print(f"âŒ Test ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {TEST_CSV}")
        exit(1)
    
    # ì•™ìƒë¸” ì œì¶œ íŒŒì¼ ìƒì„±
    # ê°€ì¤‘ì¹˜ ì‹¤í—˜ 2: XGBoost ê°ì†Œ
    weights =  [0.2, 0.4, 0.4]
    output_name = 'submission_ensemble(3model)_balanced.csv'
    create_ensemble_submission(
        test_csv=TEST_CSV,
        model_paths=MODEL_PATHS,
        weights=weights, 
        output_filename=output_name
    )