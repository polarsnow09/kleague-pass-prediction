"""
Meta-Learner í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

OOF ì˜ˆì¸¡ì„ ì‚¬ìš©í•˜ì—¬ Stacking ì•™ìƒë¸”ì˜ Meta-Learnerë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python src/models/train_meta_learner.py
"""

import pandas as pd
import numpy as np
import pickle
from pathlib import Path
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
import lightgbm as lgb

# ê²½ë¡œ ì„¤ì •
DATA_DIR = Path('data/processed')
MODEL_DIR = Path('models')
MODEL_DIR.mkdir(exist_ok=True)

print("=" * 60)
print("Meta-Learner í•™ìŠµ ì‹œì‘")
print("=" * 60)

# 1. OOF ë°ì´í„° ë¡œë“œ
print("\nğŸ“‚ OOF ë°ì´í„° ë¡œë“œ ì¤‘...")
oof_df = pd.read_csv(DATA_DIR / 'oof_predictions.csv')
print(f"âœ… Shape: {oof_df.shape}")

# 2. Meta-Features ë° íƒ€ê²Ÿ ë¶„ë¦¬
print("\nğŸ” Meta-Features ì¤€ë¹„ ì¤‘...")

# Meta-Features: 3ê°œ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ (6ê°œ)
meta_features = [
    'xgb_pred_x', 'xgb_pred_y',
    'lgb_pred_x', 'lgb_pred_y',
    'cat_pred_x', 'cat_pred_y'
]

X_meta = oof_df[meta_features].values
y_true_x = oof_df['true_x'].values
y_true_y = oof_df['true_y'].values

print(f"âœ… Meta-Features: {X_meta.shape}")
print(f"   - ìƒ˜í”Œ: {len(X_meta):,}ê°œ")
print(f"   - í”¼ì²˜: {len(meta_features)}ê°œ")

# 3. ìƒê´€ê´€ê³„ í™•ì¸
print("\nğŸ“Š Base ëª¨ë¸ ì˜ˆì¸¡ ê°„ ìƒê´€ê´€ê³„:")
corr = oof_df[meta_features].corr()
print(corr.round(3))

# -------------------------------------------------------------------
print("\n" + "=" * 60)
print("1ï¸âƒ£ Ridge Regression Meta-Learner")
print("=" * 60)

# Ridge íŒŒë¼ë¯¸í„° íƒìƒ‰
alphas = [0.1, 1.0, 10.0, 100.0]
best_alpha_x = None
best_alpha_y = None
best_score_x = float('inf')
best_score_y = float('inf')

print("\nğŸ” Alpha íŠœë‹ (end_x)...")
for alpha in alphas:
    ridge = Ridge(alpha=alpha, random_state=42)
    # Negative MSEì´ë¯€ë¡œ ìŒìˆ˜ ì œê±°
    scores = -cross_val_score(ridge, X_meta, y_true_x, 
                               cv=5, scoring='neg_mean_squared_error')
    rmse = np.sqrt(scores.mean())
    print(f"   alpha={alpha:6.1f} â†’ RMSE: {rmse:.4f}m")
    
    if rmse < best_score_x:
        best_score_x = rmse
        best_alpha_x = alpha

print(f"âœ… ìµœì  alpha (end_x): {best_alpha_x} (RMSE: {best_score_x:.4f}m)")

print("\nğŸ” Alpha íŠœë‹ (end_y)...")
for alpha in alphas:
    ridge = Ridge(alpha=alpha, random_state=42)
    scores = -cross_val_score(ridge, X_meta, y_true_y, 
                               cv=5, scoring='neg_mean_squared_error')
    rmse = np.sqrt(scores.mean())
    print(f"   alpha={alpha:6.1f} â†’ RMSE: {rmse:.4f}m")
    
    if rmse < best_score_y:
        best_score_y = rmse
        best_alpha_y = alpha

print(f"âœ… ìµœì  alpha (end_y): {best_alpha_y} (RMSE: {best_score_y:.4f}m)")

# ìµœì  íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ
print("\nğŸ“ ìµœì¢… Ridge ëª¨ë¸ í•™ìŠµ ì¤‘...")
ridge_x = Ridge(alpha=best_alpha_x, random_state=42)
ridge_y = Ridge(alpha=best_alpha_y, random_state=42)

ridge_x.fit(X_meta, y_true_x)
ridge_y.fit(X_meta, y_true_y)

# í•™ìŠµ ë°ì´í„° ì˜ˆì¸¡ (sanity check)
pred_x = ridge_x.predict(X_meta)
pred_y = ridge_y.predict(X_meta)

rmse_x = np.sqrt(mean_squared_error(y_true_x, pred_x))
rmse_y = np.sqrt(mean_squared_error(y_true_y, pred_y))
rmse_total = np.sqrt((rmse_x**2 + rmse_y**2) / 2)

print(f"\nâœ… Ridge í•™ìŠµ ì™„ë£Œ!")
print(f"   - end_x RMSE: {rmse_x:.4f}m")
print(f"   - end_y RMSE: {rmse_y:.4f}m")
print(f"   - Total RMSE: {rmse_total:.4f}m")

# Ridge ê°€ì¤‘ì¹˜ ì¶œë ¥
print(f"\nğŸ“Š Ridge ê°€ì¤‘ì¹˜ (end_x):")
for i, (feat, coef) in enumerate(zip(meta_features, ridge_x.coef_)):
    print(f"   {feat:15s}: {coef:7.4f}")
print(f"   intercept      : {ridge_x.intercept_:7.4f}")

print(f"\nğŸ“Š Ridge ê°€ì¤‘ì¹˜ (end_y):")
for i, (feat, coef) in enumerate(zip(meta_features, ridge_y.coef_)):
    print(f"   {feat:15s}: {coef:7.4f}")
print(f"   intercept      : {ridge_y.intercept_:7.4f}")

# ëª¨ë¸ ì €ì¥
ridge_path_x = MODEL_DIR / 'meta_ridge_x.pkl'
ridge_path_y = MODEL_DIR / 'meta_ridge_y.pkl'

with open(ridge_path_x, 'wb') as f:
    pickle.dump(ridge_x, f)
with open(ridge_path_y, 'wb') as f:
    pickle.dump(ridge_y, f)

print(f"\nğŸ’¾ Ridge ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
print(f"   - {ridge_path_x}")
print(f"   - {ridge_path_y}")

# -------------------------------------------------------------------
print("\n" + "=" * 60)
print("2ï¸âƒ£ LightGBM Meta-Learner (ë¹„êµìš©)")
print("=" * 60)

print("\nğŸ“ LightGBM Meta-Learner í•™ìŠµ ì¤‘...")

# LightGBM íŒŒë¼ë¯¸í„° (ê°€ë³ê²Œ)
params = {
    'objective': 'regression',
    'metric': 'rmse',
    'num_leaves': 15,  # ì‘ê²Œ (ê³¼ì í•© ë°©ì§€)
    'learning_rate': 0.05,
    'n_estimators': 100,  # ì ê²Œ
    'verbosity': -1,
    'random_state': 42
}

# end_x ëª¨ë¸
lgb_x = lgb.LGBMRegressor(**params)
lgb_x.fit(X_meta, y_true_x)
pred_x = lgb_x.predict(X_meta)
lgb_rmse_x = np.sqrt(mean_squared_error(y_true_x, pred_x))

# end_y ëª¨ë¸
lgb_y = lgb.LGBMRegressor(**params)
lgb_y.fit(X_meta, y_true_y)
pred_y = lgb_y.predict(X_meta)
lgb_rmse_y = np.sqrt(mean_squared_error(y_true_y, pred_y))

lgb_rmse_total = np.sqrt((lgb_rmse_x**2 + lgb_rmse_y**2) / 2)

print(f"\nâœ… LightGBM í•™ìŠµ ì™„ë£Œ!")
print(f"   - end_x RMSE: {lgb_rmse_x:.4f}m")
print(f"   - end_y RMSE: {lgb_rmse_y:.4f}m")
print(f"   - Total RMSE: {lgb_rmse_total:.4f}m")

# LightGBM í”¼ì²˜ ì¤‘ìš”ë„
print(f"\nğŸ“Š LightGBM í”¼ì²˜ ì¤‘ìš”ë„ (end_x):")
importances_x = lgb_x.feature_importances_
for feat, imp in sorted(zip(meta_features, importances_x), 
                        key=lambda x: x[1], reverse=True):
    print(f"   {feat:15s}: {imp:7.0f}")

print(f"\nğŸ“Š LightGBM í”¼ì²˜ ì¤‘ìš”ë„ (end_y):")
importances_y = lgb_y.feature_importances_
for feat, imp in sorted(zip(meta_features, importances_y), 
                        key=lambda x: x[1], reverse=True):
    print(f"   {feat:15s}: {imp:7.0f}")

# ëª¨ë¸ ì €ì¥
lgb_path_x = MODEL_DIR / 'meta_lgb_x.pkl'
lgb_path_y = MODEL_DIR / 'meta_lgb_y.pkl'

with open(lgb_path_x, 'wb') as f:
    pickle.dump(lgb_x, f)
with open(lgb_path_y, 'wb') as f:
    pickle.dump(lgb_y, f)

print(f"\nğŸ’¾ LightGBM ëª¨ë¸ ì €ì¥ ì™„ë£Œ:")
print(f"   - {lgb_path_x}")
print(f"   - {lgb_path_y}")

# -------------------------------------------------------------------
print("\n" + "=" * 60)
print("ğŸ“Š Meta-Learner ë¹„êµ")
print("=" * 60)

print(f"\nRidge     : {rmse_total:.4f}m")
print(f"LightGBM  : {lgb_rmse_total:.4f}m")

if rmse_total < lgb_rmse_total:
    print(f"\nğŸ† Ridgeê°€ ë” ìš°ìˆ˜! (ì°¨ì´: {lgb_rmse_total - rmse_total:.4f}m)")
    recommended = "Ridge"
else:
    print(f"\nğŸ† LightGBMì´ ë” ìš°ìˆ˜! (ì°¨ì´: {rmse_total - lgb_rmse_total:.4f}m)")
    recommended = "LightGBM"

# -------------------------------------------------------------------
print("\n" + "=" * 60)
print("ğŸ‰ Meta-Learner í•™ìŠµ ì™„ë£Œ!")
print("=" * 60)

print(f"\nâœ… ì €ì¥ëœ ëª¨ë¸:")
print(f"   - Ridge: meta_ridge_x.pkl, meta_ridge_y.pkl")
print(f"   - LightGBM: meta_lgb_x.pkl, meta_lgb_y.pkl")

print(f"\nğŸ’¡ ê¶Œì¥: {recommended} Meta-Learner ì‚¬ìš©")

print(f"\në‹¤ìŒ ë‹¨ê³„:")
print(f"1. Base ëª¨ë¸ í•™ìŠµ (ì „ì²´ ë°ì´í„°): python src/models/train_base_models.py")
print(f"2. Stacking ì˜ˆì¸¡: python src/models/predict_stacking.py --meta {recommended.lower()}")
