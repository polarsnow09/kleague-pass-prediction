"""
LightGBM ëª¨ë¸ í•™ìŠµ
Kë¦¬ê·¸ íŒ¨ìŠ¤ ì¢Œí‘œ ì˜ˆì¸¡
"""

import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
import lightgbm as lgb
import pickle
from typing import Tuple

# ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
DATA_DIR = PROJECT_ROOT / 'data' / 'processed'
MODEL_DIR = PROJECT_ROOT / 'models'


class PassCoordinateModelLGB:
    """LightGBM ê¸°ë°˜ íŒ¨ìŠ¤ ì¢Œí‘œ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self):
        self.model_x = None
        self.model_y = None
        self.feature_cols = []
        
    def prepare_features(self, df: pd.DataFrame, use_temporal: bool = True) -> Tuple[pd.DataFrame, pd.Series, pd.Series]:
        """í•™ìŠµìš© í”¼ì²˜ ì¤€ë¹„ (XGBoostì™€ ë™ì¼)"""
        df = df.copy()
        
        print(f"\nğŸ”§ í”¼ì²˜ ì¤€ë¹„ ì‹œì‘ (ì‹œê³„ì—´: {'ON' if use_temporal else 'OFF'})")
        print(f"  - ì›ë³¸ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
        
        # ë²”ì£¼í˜• í”¼ì²˜ ì¸ì½”ë”©
        zone_x_map = {'defensive': 0, 'midfield': 1, 'attacking': 2}
        zone_y_map = {'left': 0, 'center': 1, 'right': 2}
        zone_combined_map = {
            'defensive_left': 0, 'defensive_center': 1, 'defensive_right': 2,
            'midfield_left': 3, 'midfield_center': 4, 'midfield_right': 5,
            'attacking_left': 6, 'attacking_center': 7, 'attacking_right': 8
        }
        
        if 'zone_x' in df.columns and df['zone_x'].dtype == 'object':
            df['zone_x_encoded'] = df['zone_x'].map(zone_x_map)
            df['zone_y_encoded'] = df['zone_y'].map(zone_y_map)
            df['zone_combined_encoded'] = df['zone_combined'].map(zone_combined_map)
        
        # Phase 1 í”¼ì²˜
        phase1_features = [
            'start_x', 'start_y',
            'dist_to_target_goal',
            'zone_x_encoded', 'zone_y_encoded', 'zone_combined_encoded',
            'in_penalty_box', 'in_final_third',
        ]
        
        self.feature_cols = [f for f in phase1_features if f in df.columns]
        print(f"  - Phase 1 í”¼ì²˜: {len(self.feature_cols)}ê°œ")
        
        # Phase 2 í”¼ì²˜ (ì‹œê³„ì—´)
        if use_temporal:
            phase2_features = [
                'prev_end_x', 'prev_end_y',
                'prev_action_distance',
                'time_since_prev',
                'prev_direction_x', 'prev_direction_y',
                'pass_count_in_episode'
            ]
            
            temporal_added = []
            for feat in phase2_features:
                if feat in df.columns:
                    self.feature_cols.append(feat)
                    temporal_added.append(feat)
            
            print(f"  - Phase 2 í”¼ì²˜: {len(temporal_added)}ê°œ")
            if temporal_added:
                print(f"    ì¶”ê°€ëœ í”¼ì²˜: {temporal_added}")
        
        print(f"  - ìµœì¢… í”¼ì²˜ ìˆ˜: {len(self.feature_cols)}ê°œ")
        
        # NaN ì²˜ë¦¬
        X = df[self.feature_cols].copy()
        nan_counts = X.isna().sum()
        if nan_counts.sum() > 0:
            print(f"\nâš ï¸  ê²°ì¸¡ì¹˜ ë°œê²¬:")
            print(nan_counts[nan_counts > 0])
            print(f"  â†’ 0ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            X = X.fillna(0)
        
        y_x = df['end_x'].copy()
        y_y = df['end_y'].copy()
        
        return X, y_x, y_y
    
    def train(self, df: pd.DataFrame, n_folds: int = 5) -> dict:
        """Cross-validationìœ¼ë¡œ ëª¨ë¸ í•™ìŠµ"""
        print("=" * 60)
        print("ğŸš€ LightGBM ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("=" * 60)
        
        # í”¼ì²˜ ì¤€ë¹„
        X, y_x, y_y = self.prepare_features(df)
        
        print(f"\nğŸ“Š ë°ì´í„° ì •ë³´:")
        print(f"  - ìƒ˜í”Œ ìˆ˜: {len(X)}")
        print(f"  - í”¼ì²˜ ìˆ˜: {len(self.feature_cols)}")
        
        # LightGBM íŒŒë¼ë¯¸í„°
        params = {
            'objective': 'regression',
            'metric': 'rmse',
            'boosting_type': 'gbdt',
            'max_depth': 8,
            'learning_rate': 0.05,
            'n_estimators': 200,
            'num_leaves': 31,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 42,
            'verbose': -1
        }
        
        # Cross-validation
        kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
        
        cv_scores_x = []
        cv_scores_y = []
        cv_scores_total = []
        
        print(f"\nğŸ”„ {n_folds}-Fold Cross Validation:")
        
        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_x_train, y_x_val = y_x.iloc[train_idx], y_x.iloc[val_idx]
            y_y_train, y_y_val = y_y.iloc[train_idx], y_y.iloc[val_idx]
            
            # end_x ëª¨ë¸
            model_x = lgb.LGBMRegressor(**params)
            model_x.fit(
                X_train, y_x_train,
                eval_set=[(X_val, y_x_val)],
                callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]
            )
            
            # end_y ëª¨ë¸
            model_y = lgb.LGBMRegressor(**params)
            model_y.fit(
                X_train, y_y_train,
                eval_set=[(X_val, y_y_val)],
                callbacks=[lgb.early_stopping(10), lgb.log_evaluation(0)]
            )
            
            # ì˜ˆì¸¡
            pred_x = model_x.predict(X_val)
            pred_y = model_y.predict(X_val)
            
            # RMSE ê³„ì‚°
            rmse_x = np.sqrt(mean_squared_error(y_x_val, pred_x))
            rmse_y = np.sqrt(mean_squared_error(y_y_val, pred_y))
            
            # ìœ í´ë¦¬ë“œ ê±°ë¦¬ RMSE
            euclidean_errors = np.sqrt((y_x_val - pred_x)**2 + (y_y_val - pred_y)**2)
            rmse_total = np.sqrt(np.mean(euclidean_errors**2))
            
            cv_scores_x.append(rmse_x)
            cv_scores_y.append(rmse_y)
            cv_scores_total.append(rmse_total)
            
            print(f"  Fold {fold}: RMSE_X={rmse_x:.4f}m, RMSE_Y={rmse_y:.4f}m, Total={rmse_total:.4f}m")
        
        print(f"\nğŸ“ˆ Cross-validation ê²°ê³¼:")
        print(f"  - RMSE_X: {np.mean(cv_scores_x):.4f} Â± {np.std(cv_scores_x):.4f}m")
        print(f"  - RMSE_Y: {np.mean(cv_scores_y):.4f} Â± {np.std(cv_scores_y):.4f}m")
        print(f"  - RMSE_Total: {np.mean(cv_scores_total):.4f} Â± {np.std(cv_scores_total):.4f}m")
        
        # ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ
        print(f"\nğŸ”§ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        self.model_x = lgb.LGBMRegressor(**params)
        self.model_x.fit(X, y_x)
        
        self.model_y = lgb.LGBMRegressor(**params)
        self.model_y.fit(X, y_y)
        
        print(f"âœ… í•™ìŠµ ì™„ë£Œ!")
        
        # í”¼ì²˜ ì¤‘ìš”ë„
        feature_importance = pd.DataFrame({
            'feature': self.feature_cols,
            'importance_x': self.model_x.feature_importances_,
            'importance_y': self.model_y.feature_importances_
        }).sort_values('importance_x', ascending=False)
        
        print(f"\nğŸ“Š í”¼ì²˜ ì¤‘ìš”ë„ (Top 5):")
        print(feature_importance.head())
        
        # ê²°ê³¼ ì €ì¥
        results = {
            'cv_rmse_x': cv_scores_x,
            'cv_rmse_y': cv_scores_y,
            'cv_rmse_total': cv_scores_total,
            'mean_rmse_x': np.mean(cv_scores_x),
            'mean_rmse_y': np.mean(cv_scores_y),
            'mean_rmse_total': np.mean(cv_scores_total),
            'feature_importance': feature_importance,
            'feature_cols': self.feature_cols
        }
        
        return results
    
    def save(self, filename: str = 'lgb_model.pkl'):
        """ëª¨ë¸ ì €ì¥"""
        MODEL_DIR.mkdir(exist_ok=True)
        filepath = MODEL_DIR / filename
        
        with open(filepath, 'wb') as f:
            pickle.dump({
                'model_x': self.model_x,
                'model_y': self.model_y,
                'feature_cols': self.feature_cols
            }, f)
        
        print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {filepath}")


if __name__ == '__main__':
    print("ğŸ¯ Kë¦¬ê·¸ íŒ¨ìŠ¤ ì¢Œí‘œ ì˜ˆì¸¡ - LightGBM ëª¨ë¸\n")
    
    # ë°ì´í„° ë¡œë“œ
    train_path = DATA_DIR / 'train_final_passes_v2.csv'
    
    if not train_path.exists():
        print(f"âŒ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {train_path}")
        exit(1)
    
    df = pd.read_csv(train_path)
    print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ\n")
    
    # ëª¨ë¸ í•™ìŠµ
    model = PassCoordinateModelLGB()
    results = model.train(df, n_folds=5)
    
    # ëª¨ë¸ ì €ì¥
    model.save('lgb_model_v1.pkl')
    
    print("\n" + "="*60)
    print("ğŸŠ í•™ìŠµ ì™„ë£Œ!")
    print("="*60)