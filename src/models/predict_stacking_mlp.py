"""
MLP Stacking ì•™ìƒë¸” ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ predict_stacking.pyì™€ ë™ì¼í•˜ì§€ë§Œ Meta-Learnerë¡œ MLP ì‚¬ìš©

ì‚¬ìš©ë²•:
    python src/models/predict_stacking_mlp.py
"""

import pandas as pd
import numpy as np
import pickle
from pathlib import Path
from tqdm import tqdm
import xgboost as xgb
import lightgbm as lgb
import catboost as cb
from sklearn.preprocessing import LabelEncoder
import torch
import torch.nn as nn

# ê²½ë¡œ ì„¤ì •
DATA_DIR = Path('data')
RAW_DIR = DATA_DIR / 'raw'
PROCESSED_DIR = DATA_DIR / 'processed'
MODEL_DIR = Path('models')
SUBMISSION_DIR = Path('submissions')
SUBMISSION_DIR.mkdir(exist_ok=True)

# Phase í”¼ì²˜ ìƒì„± í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
import sys
sys.path.append('src')
from features.build_feature import build_baseline_features, add_previous_action_features

print("=" * 60)
print("MLP Stacking ì•™ìƒë¸” ì˜ˆì¸¡ ì‹œì‘")
print("=" * 60)

# ===================================================================
# STEP 0: MLP ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì‹œì™€ ë™ì¼)
# ===================================================================
class MLPMetaLearner(nn.Module):
    def __init__(self, input_dim=6, hidden_dim1=32, hidden_dim2=16, dropout=0.2):
        super(MLPMetaLearner, self).__init__()
        
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim1),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim1, hidden_dim2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim2, 1)
        )
    
    def forward(self, x):
        return self.network(x)

# ===================================================================
# STEP 1: Base ëª¨ë¸ í•™ìŠµ (ë™ì¼)
# ===================================================================
print("\n" + "=" * 60)
print("STEP 1: Base ëª¨ë¸ í•™ìŠµ (ì „ì²´ Train ë°ì´í„°)")
print("=" * 60)

print("\nğŸ“‚ Train ë°ì´í„° ë¡œë“œ ì¤‘...")
train_df = pd.read_csv(PROCESSED_DIR / 'train_final_passes_v4.csv')
print(f"âœ… Shape: {train_df.shape}")

# í”¼ì²˜ ë° íƒ€ê²Ÿ ë¶„ë¦¬
target_cols = ['end_x', 'end_y']
feature_cols = [col for col in train_df.columns if col not in target_cols + ['game_episode']]

# ë²”ì£¼í˜• í”¼ì²˜ ì¸ì½”ë”©
categorical_cols = train_df[feature_cols].select_dtypes(include=['object']).columns.tolist()
label_encoders = {}

if len(categorical_cols) > 0:
    print(f"\nğŸ“ ë²”ì£¼í˜• í”¼ì²˜ ì¸ì½”ë”©: {categorical_cols}")
    for col in categorical_cols:
        le = LabelEncoder()
        train_df[col] = le.fit_transform(train_df[col].astype(str))
        label_encoders[col] = le

X_train = train_df[feature_cols].values
y_train_x = train_df['end_x'].values
y_train_y = train_df['end_y'].values

print(f"âœ… í”¼ì²˜: {len(feature_cols)}ê°œ")
print(f"âœ… ìƒ˜í”Œ: {len(X_train):,}ê°œ")

# -------------------------------------------------------------------
print("\nğŸ“ XGBoost í•™ìŠµ ì¤‘...")
xgb_params = {
    'objective': 'reg:squarederror',
    'max_depth': 8,
    'learning_rate': 0.05,
    'n_estimators': 300,
    'random_state': 42
}

xgb_model_x = xgb.XGBRegressor(**xgb_params)
xgb_model_y = xgb.XGBRegressor(**xgb_params)

xgb_model_x.fit(X_train, y_train_x, verbose=False)
xgb_model_y.fit(X_train, y_train_y, verbose=False)
print("âœ… XGBoost í•™ìŠµ ì™„ë£Œ")

# -------------------------------------------------------------------
print("\nğŸ“ LightGBM í•™ìŠµ ì¤‘...")
lgb_params = {
    'objective': 'regression',
    'metric': 'rmse',
    'boosting_type': 'gbdt',
    'num_leaves': 63,
    'learning_rate': 0.03,
    'feature_fraction': 0.7,
    'bagging_fraction': 0.7,
    'bagging_freq': 5,
    'min_child_samples': 20,
    'reg_alpha': 0.1,
    'reg_lambda': 0.1,
    'verbosity': -1,
    'random_state': 42
}

train_data_x = lgb.Dataset(X_train, label=y_train_x)
train_data_y = lgb.Dataset(X_train, label=y_train_y)

lgb_model_x = lgb.train(lgb_params, train_data_x, num_boost_round=800)
lgb_model_y = lgb.train(lgb_params, train_data_y, num_boost_round=800)
print("âœ… LightGBM í•™ìŠµ ì™„ë£Œ")

# -------------------------------------------------------------------
print("\nğŸ“ CatBoost í•™ìŠµ ì¤‘...")
cat_params = {
    'iterations': 500,
    'depth': 8,
    'learning_rate': 0.05,
    'loss_function': 'RMSE',
    'random_seed': 42,
    'verbose': False
}

cat_model_x = cb.CatBoostRegressor(**cat_params)
cat_model_y = cb.CatBoostRegressor(**cat_params)

cat_model_x.fit(X_train, y_train_x, verbose=False)
cat_model_y.fit(X_train, y_train_y, verbose=False)
print("âœ… CatBoost í•™ìŠµ ì™„ë£Œ")

# ===================================================================
# STEP 2: MLP Meta-Learner ë¡œë“œ
# ===================================================================
print("\n" + "=" * 60)
print("STEP 2: MLP Meta-Learner ë¡œë“œ")
print("=" * 60)

print("\nğŸ“‚ MLP Meta-Learner ë¡œë“œ ì¤‘...")
with open(MODEL_DIR / 'meta_mlp_x.pkl', 'rb') as f:
    mlp_x_package = pickle.load(f)
with open(MODEL_DIR / 'meta_mlp_y.pkl', 'rb') as f:
    mlp_y_package = pickle.load(f)

# MLP ëª¨ë¸ ì¬êµ¬ì„±
arch = mlp_x_package['architecture']
mlp_model_x = MLPMetaLearner(**arch)
mlp_model_y = MLPMetaLearner(**arch)

mlp_model_x.load_state_dict(mlp_x_package['model_state'])
mlp_model_y.load_state_dict(mlp_y_package['model_state'])

mlp_model_x.eval()
mlp_model_y.eval()

# Scaler ë¡œë“œ
scaler = mlp_x_package['scaler']

print("âœ… MLP Meta-Learner ë¡œë“œ ì™„ë£Œ")

# ===================================================================
# STEP 3: Test ë°ì´í„° ì˜ˆì¸¡
# ===================================================================
print("\n" + "=" * 60)
print("STEP 3: Test ë°ì´í„° ì˜ˆì¸¡")
print("=" * 60)

print("\nğŸ“‚ Test ë°ì´í„° ë¡œë“œ ì¤‘...")
test = pd.read_csv(RAW_DIR / 'test.csv')
match_info = pd.read_csv(RAW_DIR / 'match_info.csv')
print(f"âœ… Test ìƒ˜í”Œ: {len(test):,}ê°œ")

# Phase 4 í†µê³„ ê³„ì‚° (ë™ì¼)
print("\nğŸ“Š Phase 4 í†µê³„ ê³„ì‚° ì¤‘...")
train_full = pd.read_csv(RAW_DIR / 'train.csv')
passes = train_full[train_full['type_name'] == 'Pass'].copy()

passes['pass_distance'] = np.sqrt(
    (passes['end_x'] - passes['start_x'])**2 + 
    (passes['end_y'] - passes['start_y'])**2
)
passes['forward_distance'] = np.where(
    passes['is_home'],
    passes['end_x'] - passes['start_x'],
    passes['start_x'] - passes['end_x']
)
passes['is_forward'] = (passes['forward_distance'] > 0).astype(int)
passes['is_success'] = (passes['result_name'] == 'Successful').astype(int)
passes['is_wide'] = ((passes['start_y'] < 20) | (passes['start_y'] > 48)).astype(int)

player_stats = passes.groupby('player_id').agg({
    'pass_distance': 'mean',
    'is_forward': 'mean',
    'is_success': 'mean',
    'player_id': 'count'
}).rename(columns={'player_id': 'pass_count'}).to_dict('index')

team_stats = passes.groupby('team_id').agg({
    'pass_distance': 'mean',
    'is_wide': 'mean'
}).rename(columns={'is_wide': 'attack_style'}).to_dict('index')

global_player = {
    'pass_distance': passes['pass_distance'].mean(),
    'is_forward': passes['is_forward'].mean(),
    'is_success': passes['is_success'].mean(),
    'pass_count': 50
}
global_team = {
    'pass_distance': passes['pass_distance'].mean(),
    'attack_style': passes['is_wide'].mean()
}

print("âœ… Phase 4 í†µê³„ ê³„ì‚° ì™„ë£Œ")

# -------------------------------------------------------------------
print("\nğŸ”® Episodeë³„ ì˜ˆì¸¡ ì‹œì‘...")

predictions = []

for idx, row in tqdm(test.iterrows(), total=len(test), desc="ì˜ˆì¸¡"):
    game_episode = row['game_episode']
    csv_path = RAW_DIR / row['path']
    
    # Episode ë°ì´í„° ë¡œë“œ
    episode_df = pd.read_csv(csv_path)
    
    # Phase 1-2 í”¼ì²˜ ìƒì„±
    episode_df = build_baseline_features(episode_df)
    episode_df = add_previous_action_features(episode_df)
    
    # Phase 3 í”¼ì²˜ ìƒì„±
    try:
        from features.advanced_features import build_phase3_features
        episode_df = build_phase3_features(episode_df)
    except ImportError:
        phase3_cols = [
            'rolling_mean_distance_3', 'rolling_std_distance_3', 
            'rolling_mean_direction_x_3', 'rolling_mean_direction_y_3',
            'rolling_mean_distance_5', 'rolling_std_distance_5',
            'rolling_mean_direction_x_5', 'rolling_mean_direction_y_5',
            'cumulative_distance', 'cumulative_forward', 'cumulative_lateral',
            'forward_lateral_ratio', 'pass_velocity', 'avg_episode_velocity',
            'velocity_change', 'recent_3_avg_velocity', 'episode_x_range',
            'episode_y_range', 'touchline_proximity', 'avg_touchline_proximity',
            'is_buildup', 'is_counter', 'is_under_pressure'
        ]
        for col in phase3_cols:
            if col not in episode_df.columns:
                episode_df[col] = 0
    
    # Phase 4 í”¼ì²˜ ì¶”ê°€ (ë™ì¼ ë¡œì§)
    last_pass = episode_df[episode_df['type_name'] == 'Pass'].iloc[-1]
    player_id = last_pass['player_id']
    team_id = last_pass['team_id']
    game_id = last_pass['game_id']
    is_home = last_pass['is_home']
    time_seconds = last_pass['time_seconds']
    
    p_stats = player_stats.get(player_id, global_player)
    episode_df['player_avg_pass_distance'] = p_stats['pass_distance']
    episode_df['player_forward_ratio'] = p_stats['is_forward']
    episode_df['player_success_rate'] = p_stats['is_success']
    episode_df['player_pass_count'] = p_stats['pass_count']
    
    t_stats = team_stats.get(team_id, global_team)
    episode_df['team_avg_pass_distance'] = t_stats['pass_distance']
    episode_df['team_attack_style'] = t_stats['attack_style']
    
    match = match_info[match_info['game_id'] == game_id].iloc[0]
    episode_df['score_diff'] = np.where(
        is_home,
        match['home_score'] - match['away_score'],
        match['away_score'] - match['home_score']
    )
    episode_df['match_period_normalized'] = time_seconds / 5400
    episode_df['is_late_game'] = int(time_seconds >= 4050)
    
    final_pass = episode_df[episode_df['type_name'] == 'Pass'].iloc[-1:].copy()
    
    # ë²”ì£¼í˜• ì¸ì½”ë”©
    for col in categorical_cols:
        if col in final_pass.columns:
            le = label_encoders[col]
            val = str(final_pass[col].values[0])
            if val in le.classes_:
                final_pass[col] = le.transform([val])[0]
            else:
                final_pass[col] = 0
    
    X_test = final_pass[feature_cols].values
    
    # Base ëª¨ë¸ ì˜ˆì¸¡
    xgb_pred_x = xgb_model_x.predict(X_test)[0]
    xgb_pred_y = xgb_model_y.predict(X_test)[0]
    
    lgb_pred_x = lgb_model_x.predict(X_test)[0]
    lgb_pred_y = lgb_model_y.predict(X_test)[0]
    
    cat_pred_x = cat_model_x.predict(X_test)[0]
    cat_pred_y = cat_model_y.predict(X_test)[0]
    
    # Meta-Features êµ¬ì„±
    meta_features = np.array([[
        xgb_pred_x, xgb_pred_y,
        lgb_pred_x, lgb_pred_y,
        cat_pred_x, cat_pred_y
    ]])
    
    # ì •ê·œí™” (MLPìš©)
    meta_features_scaled = scaler.transform(meta_features)
    meta_tensor = torch.FloatTensor(meta_features_scaled)
    
    # MLP ìµœì¢… ì˜ˆì¸¡
    with torch.no_grad():
        final_x = mlp_model_x(meta_tensor).item()
        final_y = mlp_model_y(meta_tensor).item()
    
    predictions.append({
        'game_episode': game_episode,
        'end_x': final_x,
        'end_y': final_y
    })

print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions):,}ê°œ")

# ===================================================================
# STEP 4: ì œì¶œ íŒŒì¼ ìƒì„±
# ===================================================================
print("\n" + "=" * 60)
print("STEP 4: ì œì¶œ íŒŒì¼ ìƒì„±")
print("=" * 60)

submission = pd.DataFrame(predictions)
submission = submission[['game_episode', 'end_x', 'end_y']]

output_path = SUBMISSION_DIR / 'submission_stacking_mlp.csv'
submission.to_csv(output_path, index=False)

print(f"\nğŸ’¾ ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ:")
print(f"   {output_path}")
print(f"   Shape: {submission.shape}")

print("\nğŸ“Š ì˜ˆì¸¡ í†µê³„:")
print(submission.describe())

# ===================================================================
print("\n" + "=" * 60)
print("ğŸ‰ MLP Stacking ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ!")
print("=" * 60)

print(f"\nâœ… ì œì¶œ íŒŒì¼: {output_path}")
print(f"\në‹¤ìŒ ë‹¨ê³„:")
print(f"1. ì œì¶œ íŒŒì¼ í™•ì¸")
print(f"2. ë¦¬ë”ë³´ë“œ ì œì¶œ")
print(f"3. Phase 5 (LGB) vs Phase 5.1 (MLP) ë¹„êµ")
