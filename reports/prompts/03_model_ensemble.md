# 프롬프트 로그 #03: 모델 앙상블 전략

## 날짜
2025-12-13 ~ 2025-12-14

## 목적
단일 모델의 한계를 극복하고 다양한 모델의 장점을 결합하여 성능 향상

---

## 사용한 프롬프트

### 프롬프트 3-1: LightGBM 추가 동기
```
현재 XGBoost 모델(CV 18.88m)로 첫 제출을 완료했습니다.
Public LB는 17.23으로 상위 58%입니다.

질문:
1. 단일 모델 개선 vs 앙상블 접근 중 어느 것이 효율적일까요?
2. LightGBM을 추가한다면 XGBoost와 어떤 차별점이 있을까요?
3. 앙상블 시 기대 개선폭은?
```

### Claude 응답 요약

**1. 앙상블 우선 추천**
- 단일 모델 개선: 0.3-0.8m (시간 많이 소요)
- 앙상블: 0.3-0.7m (빠르게 구현)
- 앙상블 후 개별 모델 튜닝이 효율적

**2. LightGBM vs XGBoost 차이**
- **학습 방식**: 
  - XGBoost: Level-wise (깊이 우선)
  - LightGBM: Leaf-wise (효율 우선)
- **피처 처리**:
  - XGBoost: 범주형 수동 인코딩
  - LightGBM: 자동 처리 가능
- **속도**: LightGBM이 2-3배 빠름

**3. 기대 효과**
- 단독 성능: 비슷 (~18.8m)
- 앙상블 효과: 0.1-0.3m 개선
- 다양성 확보로 일반화 향상

### 채택한 전략
- ✅ LightGBM 추가 개발
- ✅ 2-model 앙상블 구현
- ✅ 균등 가중치(0.5, 0.5) 시작

---

### 프롬프트 3-2: 앙상블 가중치 전략
```
XGBoost(CV 18.88m)와 LightGBM(CV 18.81m)의 2-model 앙상블을 구현했습니다.

질문:
1. 균등 가중치 vs 성능 비례 가중치 중 어느 것이 나을까요?
2. 가중치 최적화는 어떻게 해야 할까요?
3. 3개 모델 앙상블로 확장 시 고려사항은?
```

### Claude 응답 요약

**1. 초기 전략**
- 균등 가중치 추천 (간단하고 안정적)
- CV 차이 작음 (0.07m) → 균등도 효과적
- 과최적화 방지

**2. 가중치 최적화 방법**
- Grid Search: [0.3-0.7] 범위, 0.1 단위
- CV 기반 검증 (OOF predictions)
- LB 직접 테스트 (2-3회 제한)

**3. 3-model 확장**
- CatBoost 추가 권장
- 피처 중요도 다양성 확보
- 균등 가중치(1/3, 1/3, 1/3) 시작

### 채택한 전략
- ✅ 균등 가중치로 시작
- ✅ CatBoost 추가 계획
- ⏳ 가중치 튜닝은 필요 시

---

### 프롬프트 3-3: CatBoost 추가 전략
```
XGBoost + LightGBM 앙상블이 LB 17.13을 달성했습니다.
CatBoost를 추가하여 3-model 앙상블을 구성하려 합니다.

질문:
1. CatBoost의 강점은 무엇인가요?
2. 3개 모델의 피처 중요도가 다르면 좋은 건가요?
3. 예상 개선폭은?
```

### Claude 응답 요약

**1. CatBoost 강점**
- **범주형 처리**: 자동 인코딩 (Ordered TS)
- **과적합 방지**: Ordered boosting
- **안정성**: 하이퍼파라미터 민감도 낮음
- **GPU 지원**: 빠른 학습

**2. 피처 중요도 다양성의 의미**
- ✅ **매우 좋은 신호!**
- 각 모델이 다른 패턴 학습
- 앙상블 효과 극대화
- 일반화 성능 향상

**실제 결과:**
```
XGBoost:  zone_x (82%) 압도적
LightGBM: start_x, time_since_prev 균형
CatBoost: start_x (37%) 압도적
```
→ 완전히 다른 학습 전략! ✨

**3. 예상 개선**
- 보수적: 0.05-0.10m
- 낙관적: 0.10-0.20m
- 목표: LB 17.0 돌파

### 채택한 전략
- ✅ CatBoost 추가 (depth=8, lr=0.05)
- ✅ 3-model 균등 가중치
- ✅ 피처 중요도 분석

---

## 실험 결과

### LightGBM 모델 (Day 3)

**성능:**
- CV RMSE: 18.81m (XGBoost 대비 -0.07m)
- 학습 시간: 3분 (XGBoost의 60%)

**피처 중요도 특징:**
```
Top 5:
1. start_x (934)
2. time_since_prev (658) ← 시계열!
3. prev_direction_x (650) ← 시계열!
4. start_y (644)
5. prev_direction_y (581) ← 시계열!
```

**핵심 인사이트:**
- 시계열 피처를 XGBoost보다 잘 활용
- 균형잡힌 피처 중요도 분포
- 과적합 징후 없음

### 2-Model 앙상블 (Day 3)

**성능:**
- Public LB: 17.13 (단일 17.23 대비 -0.10)
- 순위: 278/487 (↑4 positions)

**전략:**
- 균등 가중치 [0.5, 0.5]
- 추론 시간: 1m 26s

**결과:**
- ✅ 예상 범위 내 개선
- ✅ CV와 LB 일관성 유지
- ✅ 안정적 예측 분포

### CatBoost 모델 (Day 4)

**성능:**
- CV RMSE: 18.97m (가장 높음)
- 학습 시간: 4분

**피처 중요도 특징:**
```
Top 5:
1. start_x (37.4) ← 압도적!
2. time_since_prev (11.4)
3. prev_direction_x (6.1)
4. prev_action_distance (5.6)
5. prev_end_x (5.5)
```

**핵심 인사이트:**
- start_x에 큰 비중 (XGBoost zone_x와 대조)
- 시계열 피처도 활용
- 가장 다른 학습 패턴

### 3-Model 앙상블 (Day 4)

**성능:**
- Public LB: **17.03** 🎯
- vs 2-model: -0.10 (0.6% 추가 개선)
- vs 단일 XGB: -0.20 (1.2% 총 개선)

**전략:**
- 균등 가중치 [0.33, 0.33, 0.33]
- 추론 시간: 1m 37s

**결과:**
- ✅ **LB 17.0 돌파!**
- ✅ 예상 범위 내 개선
- ✅ 3개 모델 다양성 효과 검증

---

## 핵심 학습

### 1. 모델 다양성의 중요성

**피처 중요도 비교:**
```
XGBoost:  zone_x(82%) > start_x(8%)
LightGBM: start_x(30%) ≈ temporal(25%)
CatBoost: start_x(37%) > temporal(30%)
```

→ **완전히 다른 관점으로 패턴 학습!**

### 2. 앙상블의 일반화 효과
```
개별 CV: 18.88 / 18.81 / 18.97 (평균 18.89)
2-model LB: 17.13 (CV 대비 -1.68)
3-model LB: 17.03 (CV 대비 -1.86)

→ 앙상블이 일반화 성능 향상!
```

### 3. 점진적 개선의 효과
```
Day 3 AM: 17.23 (단일)
Day 3 PM: 17.13 (2-model, -0.10)
Day 4: 17.03 (3-model, -0.10)

→ 작은 개선의 누적 = 큰 효과!
```

### 4. 가중치 전략

**균등 가중치의 장점:**
- 구현 간단
- 과최적화 방지
- 안정적 성능
- 해석 용이

**결론:** 초기 단계에서는 균등 가중치가 효율적

---

## 다음 단계

### 단기 (완료 또는 진행중)
- ✅ LightGBM 추가
- ✅ 2-model 앙상블
- ✅ CatBoost 추가
- ✅ 3-model 앙상블
- ✅ LB 17.0 돌파 ✨

### 중기 (계획)
- [ ] 가중치 최적화 (Grid Search)
- [ ] 고급 시계열 피처 추가
  - 최근 N개 패스 통계
  - 방향 변화 패턴
  - 속도 관련 피처
- [ ] 하이퍼파라미터 튜닝 (Optuna)

### 장기 (고려중)
- [ ] 딥러닝 모델 (LSTM)
- [ ] Stacking 앙상블
- [ ] 도메인 특화 피처
  - 선수별 스타일
  - 팀별 전술
  - 경기 흐름

---

## 비용 대비 효과 분석

| 작업 | 소요 시간 | 개선폭 | 효율성 |
|------|----------|--------|--------|
| LightGBM 개발 | 40분 | 0.10 | ⭐⭐⭐⭐⭐ |
| 2-model 앙상블 | 20분 | 0.10 | ⭐⭐⭐⭐⭐ |
| CatBoost 개발 | 30분 | 0.10 | ⭐⭐⭐⭐ |

**총 투자:** 1.5시간  
**총 개선:** 0.20 (1.2%)  
**효율성:** 매우 높음! ✨

---

## 회고

### 잘한 점
1. ✅ 빠른 이터레이션 (3일 내 3회 제출)
2. ✅ 체계적 실험 (단일 → 2개 → 3개)
3. ✅ 다양성 확보 (피처 중요도 분석)
4. ✅ 과최적화 방지 (균등 가중치)

### 개선점
1. ⚠️ CV와 LB 차이 커짐 (1.86m)
   - 원인: 앙상블 일반화 효과 or Train/Test 분포 차이
   - 대응: 추가 검증 필요
2. ⚠️ CatBoost CV 성능 낮음
   - 원인: 하이퍼파라미터 미튜닝
   - 대응: 튜닝으로 개선 가능

### 다음 전략
- CV와 LB 간격 모니터링
- 개별 모델 성능 향상
- 고급 피처로 ceiling 높이기

---

## 참고 자료

### 프롬프트 히스토리
- 총 40+ 프롬프트 사용
- 평균 응답 시간: 30초
- 채택률: 85%

### 코드 파일
- `src/models/train_model_lgb.py`
- `src/models/train_model_catboost.py`
- `src/models/predict_ensemble.py`

### 결과 파일
- `submissions/submission_ensemble_xgb_lgb.csv` (LB 17.13)
- `submissions/submission_ensemble_3models.csv` (LB 17.03)