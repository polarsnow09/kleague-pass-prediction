# í”„ë¡¬í”„íŠ¸ ë¡œê·¸ #09: Phase 5.1 - MLP Meta-Learner

## ë‚ ì§œ
2026-01-03 ~ 2026-01-06

## ëª©ì 
Phase 5 Stacking ì•™ìƒë¸”ì˜ Meta-Learnerë¥¼ Neural Network(MLP)ë¡œ êµì²´í•˜ì—¬ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ ì‹œë„

---

## ë°°ê²½

### Phase 5 í˜„í™©
```
XGBoost v4:  18.73m
LightGBM v4: 18.64m
CatBoost v4: 18.73m
Stacking v5: 16.5316m (LB) ğŸ¥‡ ìµœê³  ê¸°ë¡
Meta-Learner: LightGBM (12.84m OOF)
```

### ê°€ì„¤
> "Neural Networkê°€ Base ëª¨ë¸ ê°„ ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ë¥¼ 
> ë” ì˜ í•™ìŠµí•˜ì—¬ ì„±ëŠ¥ì„ ê°œì„ í•  ìˆ˜ ìˆì„ ê²ƒ"

---

## í”„ë¡¬í”„íŠ¸ 1: ë‹¤ìŒ ë°©í–¥ì„± ì œì•ˆ

### ì…ë ¥
```
Phase 5ê¹Œì§€ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤:
- Stacking ì•™ìƒë¸”: 16.5316m (LB)
- Meta-Learner: Ridge vs LightGBM ë¹„êµ ì™„ë£Œ

Phase 6(ì—ëŸ¬ ë¶„ì„ í”¼ì²˜)ëŠ” 16.5622mìœ¼ë¡œ ì•…í™”ë˜ì—ˆìŠµë‹ˆë‹¤.

ë‹¤ìŒ ë‹¨ê³„ë¡œ ì–´ë–¤ ì ‘ê·¼ì´ ì¢‹ì„ê¹Œìš”?
```

### Claude ì‘ë‹µ ìš”ì•½
```
ì˜µì…˜ A: Phase 5 ê°œì„  (ì•ˆì „í•œ ì ‘ê·¼) â­ ì¶”ì²œ
1. ë‹¤ë¥¸ Meta-Learner ì‹¤í—˜
   - Neural Network (MLP)
   - XGBoost Meta-Model
   - ì˜ˆìƒ íš¨ê³¼: 0.05-0.1m

2. Base ëª¨ë¸ ë‹¤ì–‘ì„± ì¦ëŒ€
   - 6-model Stacking
   - ì˜ˆìƒ íš¨ê³¼: 0.1-0.2m

3. 2-Level Stacking
   - Level 0 â†’ Level 1 â†’ Level 2
   
ì¶”ì²œ ì´ìœ :
- Phase 5ê°€ ì´ë¯¸ ê²€ì¦ëœ ìµœê³  ì„±ëŠ¥
- êµ¬ì¡°ì  ê°œì„ ì´ í”¼ì²˜ë³´ë‹¤ íš¨ê³¼ì 
- ì•ˆì „í•˜ë©´ì„œë„ ê°œì„  ì—¬ì§€ ì¶©ë¶„
```

### ì±„íƒí•œ ì „ëµ
- âœ… ì˜µì…˜ A-1: MLP Meta-Learner ì‹œë„
- ì´ìœ : êµ¬í˜„ ì‹œê°„ 1-2ì‹œê°„, ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ íšë“ ê°€ëŠ¥

---

## í”„ë¡¬í”„íŠ¸ 2: MLP Meta-Learner ì„¤ê³„

### ì…ë ¥
```
MLP Meta-Learnerë¥¼ êµ¬í˜„í•˜ë ¤ê³  í•©ë‹ˆë‹¤.
ê¸°ì¡´ Ridge/LightGBMê³¼ ë¹„êµí•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„í•´ì£¼ì„¸ìš”.

Input: 6ê°œ í”¼ì²˜ (3 models Ã— 2 coordinates)
Output: end_x, end_y
```

### Claude ì‘ë‹µ (í•µì‹¬ êµ¬ì¡°)
```python
Architecture:
Input (6) â†’ Hidden (32) â†’ ReLU â†’ Dropout(0.2) 
         â†’ Hidden (16) â†’ ReLU â†’ Dropout(0.2)
         â†’ Output (1)

í•µì‹¬ ì„¤ê³„:
1. 2-layer MLP (ê¹Šì§€ ì•Šê²Œ)
   - ì´ìœ : ë©”íƒ€ í”¼ì²˜ 6ê°œë§Œ, ê³¼ì í•© ë°©ì§€
   
2. Dropout 0.2
   - ì´ìœ : ìƒ˜í”Œ ìˆ˜(15,435ê°œ) ëŒ€ë¹„ ì•ˆì „

3. StandardScaler
   - ì´ìœ : Neural NetworkëŠ” ì •ê·œí™” í•„ìˆ˜

4. Early Stopping
   - patience=20
   - ì´ìœ : ê³¼ì í•© ë°©ì§€

5. Learning Rate Scheduler
   - ReduceLROnPlateau
   - ì´ìœ : ìë™ í•™ìŠµë¥  ì¡°ì •
```

---

## êµ¬í˜„ ê³¼ì •

### íŒŒì¼ ìƒì„±
1. `src/models/train_meta_learner_mlp.py` âœ…
2. `src/models/predict_stacking_mlp.py` âœ…

### í•µì‹¬ ì½”ë“œ
```python
class MLPMetaLearner(nn.Module):
    def __init__(self, input_dim=6, hidden_dim1=32, 
                 hidden_dim2=16, dropout=0.2):
        super(MLPMetaLearner, self).__init__()
        
        self.network = nn.Sequential(
            nn.Linear(input_dim, hidden_dim1),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim1, hidden_dim2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim2, 1)
        )
    
    def forward(self, x):
        return self.network(x)
```

### í•™ìŠµ ì„¤ì •
- Optimizer: Adam (lr=0.001, weight_decay=1e-4)
- Loss: MSE
- Batch Size: 256
- Max Epochs: 100
- Early Stopping: patience=20

---

## ì‹¤í–‰ ì¤‘ ì´ìŠˆ

### Issue 1: PyTorch ë²„ì „ ì˜¤ë¥˜
**ì—ëŸ¬:**
```python
TypeError: ReduceLROnPlateau.__init__() got an unexpected 
keyword argument 'verbose'
```

**ì›ì¸:**
- PyTorch ìµœì‹  ë²„ì „ì—ì„œ `verbose` íŒŒë¼ë¯¸í„° ì œê±°ë¨

**í•´ê²°:**
```python
# ìˆ˜ì • ì „
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10, verbose=True
)

# ìˆ˜ì • í›„
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10
)
```

---

## ì‹¤í—˜ ê²°ê³¼

### OOF ì„±ëŠ¥ (Train ë°ì´í„°)
```
Ridge     : 13.19m
LightGBM  : 12.84m â† ê¸°ì¡´ ìµœê³ 
MLP       : 12.??m (ì‹¤ì œ ê°’ ê¸°ë¡ í•„ìš”)

â†’ MLP OOF ì„±ëŠ¥ì€ í™•ì¸ í•„ìš”
```

### Public LB (Test ë°ì´í„°)
```
Phase 5 (LGB):   16.5316m ğŸ¥‡ ìµœê³ 
Phase 6 (ì—ëŸ¬):  16.5622m
Phase 5.1 (MLP): 16.7311m âŒ ê°€ì¥ ë‚˜ì¨

ì•…í™”: +0.20m (1.2%)
```

---

## ì‹¤íŒ¨ ì›ì¸ ë¶„ì„

### 1. ê³¼ì í•© (Overfitting to OOF)
```
ê°€ì„¤: MLPê°€ Train(OOF) ë°ì´í„°ì— ê³¼ì í•©

ì¦ê±°:
- OOF ì„±ëŠ¥: ì¢‹ì„ ê°€ëŠ¥ì„± (í™•ì¸ í•„ìš”)
- LB ì„±ëŠ¥: 16.73m (ë‚˜ì¨)
- ì°¨ì´ê°€ í´ìˆ˜ë¡ ê³¼ì í•© ì‹¬ê°

ì›ì¸:
- Neural Networkì˜ ë†’ì€ í‘œí˜„ë ¥
- ì ì€ ìƒ˜í”Œ ìˆ˜(15,435ê°œ)
- Dropout/Regularization ë¶€ì¡±
```

### 2. ë©”íƒ€ í”¼ì²˜ì˜ ë‹¨ìˆœì„±
```
ë©”íƒ€ í”¼ì²˜: 6ê°œë§Œ (xgb_x, xgb_y, lgb_x, lgb_y, cat_x, cat_y)

ë¬¸ì œ:
- Neural NetworkëŠ” ê³ ì°¨ì› í”¼ì²˜ì— ê°•í•¨
- 6ê°œ ì €ì°¨ì›ì—ì„œëŠ” ì˜¤íˆë ¤ ë¶ˆë¦¬
- LightGBM/Ridgeê°€ ë” ì í•©

ë¹„ìœ :
"ë§ì¹˜ë¡œ ëª» ë°•ê¸°" vs "ë§ì¹˜ë¡œ ë‚˜ì‚¬ ì¡°ì´ê¸°"
â†’ MLPëŠ” ë³µì¡í•œ ë¬¸ì œì— ì í•©, ë‹¨ìˆœ ë¬¸ì œì—” ê³¼í•¨
```

### 3. Base ëª¨ë¸ ì˜ˆì¸¡ì˜ ë†’ì€ ìƒê´€ê´€ê³„
```
Base ëª¨ë¸ ê°„ ìƒê´€ê³„ìˆ˜: 0.98+

ì˜ë¯¸:
- ê±°ì˜ ë™ì¼í•œ ì˜ˆì¸¡
- ë¹„ì„ í˜• ì¡°í•©ì˜ ì´ë“ ì œí•œì 
- ì„ í˜• ì¡°í•©(Ridge)ì´ë‚˜ Tree(LGB)ë¡œ ì¶©ë¶„

MLPì˜ ê°•ì  ë°œíœ˜ ì¡°ê±´:
- ìƒê´€ê´€ê³„ ë‚®ìŒ (< 0.9)
- ìƒí™©ë³„ ë‹¤ë¥¸ ìµœì  ëª¨ë¸
- ë³µì¡í•œ ìƒí˜¸ì‘ìš©
```

### 4. ì•™ìƒë¸” ë‹¤ì–‘ì„± ë¶€ì¡±
```
3ê°œ Base ëª¨ë¸:
- ëª¨ë‘ Gradient Boosting ê³„ì—´
- ë¹„ìŠ·í•œ ì˜ˆì¸¡ íŒ¨í„´
- ë¹„ì„ í˜• Meta-Learnerì˜ ì´ë“ ì œí•œ

í•„ìš”:
- ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜(Random Forest, SVM ë“±)
- ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
- ë‹¤ë¥¸ í”¼ì²˜ ì¡°í•©
```

---

## í•µì‹¬ í•™ìŠµ

### 1. ë” ë³µì¡í•œ ëª¨ë¸ â‰  ë” ì¢‹ì€ ì„±ëŠ¥
```
Ridge (ì„ í˜•):     13.19m â†’ LB ì¢‹ìŒ
LightGBM (ë¹„ì„ í˜•): 12.84m â†’ LB 16.53m âœ…
MLP (ë¹„ì„ í˜•):     12.??m â†’ LB 16.73m âŒ

êµí›ˆ:
- OOF ì„±ëŠ¥ â‰  LB ì„±ëŠ¥
- ë‹¨ìˆœí•œ ëª¨ë¸ì´ ì¼ë°˜í™” ì˜í•¨
- ë¬¸ì œ ë³µì¡ë„ì— ë§ëŠ” ëª¨ë¸ ì„ íƒ ì¤‘ìš”
```

### 2. Meta-Learningì˜ í•œê³„
```
Meta-Featuresê°€ ë‹¨ìˆœí•  ë•Œ:
- ì„ í˜• ì¡°í•©(Ridge)ìœ¼ë¡œ ì¶©ë¶„
- Tree(LightGBM)ê°€ ì ë‹¹
- Neural NetworkëŠ” ê³¼í•¨

ë³µì¡í•œ Meta-Features í•„ìš”:
- Base ëª¨ë¸ ë‹¤ì–‘í™”
- í”¼ì²˜ ì¶”ê°€ (ì‹œê°„, ìœ„ì¹˜, ìƒí™© ë“±)
- ì¡°ê±´ë¶€ ì•™ìƒë¸”
```

### 3. Stackingì˜ ìµœì ì 
```
Phase 5 (LightGBM Meta):
- Base 3ê°œ ëª¨ë¸
- ë©”íƒ€ í”¼ì²˜ 6ê°œ
- LightGBM Meta-Learner

â†’ ì´ë¯¸ ìµœì ì˜ ê· í˜•!
â†’ ì¶”ê°€ ë³µì¡ë„ëŠ” ì—­íš¨ê³¼
```

### 4. ì‹¤í—˜ì˜ ê°€ì¹˜
```
"ì‹¤íŒ¨í•œ ì‹¤í—˜"ë„ ì¤‘ìš”í•œ ì •ë³´:

âœ… MLP Meta-LearnerëŠ” íš¨ê³¼ ì—†ìŒ
âœ… Phase 5ê°€ ê²¬ê³ í•¨ í™•ì¸
âœ… ë‹¤ìŒ ë°©í–¥ì„± ëª…í™•í™”
   â†’ í”¼ì²˜ ë‹¤ì–‘í™”ë³´ë‹¤
   â†’ Base ëª¨ë¸ ë‹¤ì–‘í™”ê°€ í•„ìš”
```

---

## ë‹¤ìŒ ë‹¨ê³„ (ë¯¸êµ¬í˜„)

### ì œì™¸í•  ì˜µì…˜
- âŒ MLP Meta-Learner ì¶”ê°€ íŠœë‹
- âŒ ë” ê¹Šì€ Neural Network
- âŒ Attention Mechanism

### ê³ ë ¤í•  ì˜µì…˜

**ì˜µì…˜ 1: 6-Model Stacking** â­ ì¶”ì²œ
```
í˜„ì¬: XGB, LGB, Cat (ê° 1ê°œ)
ë³€ê²½: XGBÃ—2, LGBÃ—2, CatÃ—2 (ê°ê¸° ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°)

ì¥ì :
- Base ëª¨ë¸ ë‹¤ì–‘ì„± ì¦ê°€
- ë©”íƒ€ í”¼ì²˜ 12ê°œë¡œ í™•ì¥
- ê²€ì¦ëœ ì•Œê³ ë¦¬ì¦˜ í™œìš©

ì˜ˆìƒ: 0.1-0.2m ê°œì„ 
```

**ì˜µì…˜ 2: ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ ì¶”ê°€**
```
ì¶”ê°€: Random Forest, ExtraTrees
ì´ìœ : Boostingê³¼ ë‹¤ë¥¸ í•™ìŠµ ë°©ì‹

ì˜ˆìƒ: 0.05-0.15m ê°œì„ 
```

**ì˜µì…˜ 3: Phase 5 ìœ ì§€ ë° ë¬¸ì„œí™”**
```
ê²°ì •: Phase 5ê°€ ì¶©ë¶„íˆ ì¢‹ìŒ
í–‰ë™: í”„ë¡œì íŠ¸ ë§ˆë¬´ë¦¬ ë° ì •ë¦¬

ì´ìœ :
- 16.53mì€ ê²½ìŸë ¥ ìˆëŠ” ì„±ëŠ¥
- ì¶”ê°€ ê°œì„ ì˜ íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ë¶ˆí™•ì‹¤
- ì‹œê°„ì„ ë¬¸ì„œí™”/í¬íŠ¸í´ë¦¬ì˜¤ì— íˆ¬ì
```

---

## íšŒê³ 

### ì˜í•œ ì 
1. âœ… ì²´ê³„ì  ì‹¤í—˜ ì„¤ê³„
2. âœ… ì½”ë“œ ì¬ì‚¬ìš©ì„± (predict_stacking_mlp.py)
3. âœ… ë¹ ë¥¸ ì´í„°ë ˆì´ì…˜ (1ì¼ ë‚´ ì™„ë£Œ)
4. âœ… ì‹¤íŒ¨ë¥¼ í†µí•œ í•™ìŠµ

### ì•„ì‰¬ìš´ ì 
1. âš ï¸ OOF ì„±ëŠ¥ ë¨¼ì € í™•ì¸í–ˆì–´ì•¼ í•¨
   - OOFì™€ LB ì°¨ì´ë¡œ ê³¼ì í•© ì¡°ê¸° ë°œê²¬ ê°€ëŠ¥
2. âš ï¸ Base ëª¨ë¸ ìƒê´€ê´€ê³„ ì¬í™•ì¸ ì•ˆí•¨
   - 0.98+ ìƒê´€ê´€ê³„ë©´ ë¹„ì„ í˜• ë¶ˆí•„ìš” ì˜ˆì¸¡ ê°€ëŠ¥

### ë°°ìš´ ì 

> **"Stackingì—ì„œ Meta-LearnerëŠ” 
> Base ëª¨ë¸ ë‹¤ì–‘ì„±ë§Œí¼ë§Œ ë³µì¡í•´ì•¼ í•œë‹¤"**
> 
> Base ëª¨ë¸ì´ ë¹„ìŠ·í•˜ë©´:
> - ì„ í˜•/Treeë¡œ ì¶©ë¶„
> 
> Base ëª¨ë¸ì´ ë‹¤ì–‘í•˜ë©´:
> - Neural Network íš¨ê³¼ì 

> **"ì‹¤íŒ¨ëŠ” ì„±ê³µì˜ ì–´ë¨¸ë‹ˆ"**
> 
> Phase 5.1 ì‹¤íŒ¨ë¥¼ í†µí•´:
> - Phase 5ì˜ ìš°ìˆ˜ì„± ì¬í™•ì¸
> - ë‹¤ìŒ ë°©í–¥ì„± ëª…í™•í™”
> - Meta-Learningì˜ í•œê³„ ì´í•´

---

## ì°¸ê³  ìë£Œ

### ì½”ë“œ íŒŒì¼
- `src/models/train_meta_learner_mlp.py`
- `src/models/predict_stacking_mlp.py`

### ëª¨ë¸ íŒŒì¼
- `models/meta_mlp_x.pkl`
- `models/meta_mlp_y.pkl`

### ì œì¶œ íŒŒì¼
- `submissions/submission_stacking_mlp.csv` (LB 16.7311)

---

## í”„ë¡¬í”„íŠ¸ í†µê³„

- ì´ í”„ë¡¬í”„íŠ¸ ìˆ˜: 5ê°œ
- Phase 5.1 ê´€ë ¨: 3ê°œ (í•µì‹¬)
- ì˜¤ë¥˜ ìˆ˜ì •: 1íšŒ (PyTorch verbose)
- í‰ê·  ì‘ë‹µ ì‹œê°„: 30ì´ˆ
- ì±„íƒë¥ : 100%

---

**ğŸ”š Phase 5.1 ì¢…ë£Œ**

ë¹„ë¡ ì„±ëŠ¥ì€ ì•…í™”ë˜ì—ˆì§€ë§Œ,
ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤:

```
"ìµœê³ ì˜ ë°©ë²•ì€ í•­ìƒ ê°€ì¥ ë³µì¡í•œ ë°©ë²•ì´ ì•„ë‹ˆë‹¤.
ë¬¸ì œì— ë§ëŠ” ì ì ˆí•œ ë³µì¡ë„ê°€ ìµœê³ ë‹¤."

Phase 5 (Simple Meta-Learner) = 16.53m âœ…
Phase 5.1 (Complex Meta-Learner) = 16.73m âŒ
```

**ë‹¤ìŒ ëª©í‘œ: Phase 5 ìœ ì§€ ë° í”„ë¡œì íŠ¸ ë§ˆë¬´ë¦¬ ë˜ëŠ” 6-Model Stacking ì‹œë„**
